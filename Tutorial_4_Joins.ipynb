{"cells":[{"cell_type":"markdown","source":["### Joins\n* A join brings together two sets of data, the left and the right, by comparing the value of one or more keys of the left and right and <evaluating the result of a join expression that determines whether Spark should bring together the left set of data with the right set of data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7db0e9a5-74db-4838-b3cb-73653bd5b25c"}}},{"cell_type":"markdown","source":["`Syntax`"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c3872af7-246e-4e2d-98ae-c5bd74608adb"}}},{"cell_type":"markdown","source":["`join(other, on=None, how=None)[source]`\n\n##### Joins with another DataFrame, using the given join expression.\n\n##### Parameters\n* other – Right side of the join\n\n* on – a string for the join column name, a list of column names, a join expression (Column), or a list of Columns. If on is a string or a list of strings indicating the name of the join column(s), the column(s) must exist on both sides, and this performs an equi-join.\n\n* how – str, default inner. Must be one of: `inner`, `cross`, `outer`, `full`, `fullouter`, `full_outer`, `left`, `leftouter`, `left_outer`, `right`, `rightouter`, `right_outer`, `semi`, `leftsemi`, `left_semi`, `anti`, `leftanti` and `left_anti`."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cdd6ff7f-2dd6-4d01-b64b-15d832159742"}}},{"cell_type":"markdown","source":["### Join Types\n* Whereas the join expression determines whether two rows should join, the join type determines what should be in the result set.\n##### INNER JOIN\n* The inner join is the default join in Spark SQL. It selects rows that have matching values in both relations.\n##### CROSS JOIN\n* A cross join returns the Cartesian product of two relations.\n##### LEFT JOIN\n* A left join returns all values from the left relation and the matched values from the right relation, or appends NULL if there is no match. It is also referred to as a left outer join.\n##### RIGHT JOIN\n* A right join returns all values from the right relation and the matched values from the left relation, or appends NULL if there is no match. It is also referred to as a right outer join\n##### FULL JOIN\n* A full join returns all values from both relations, appending NULL values on the side that does not have a match. It is also referred to as a full outer join.\n##### SEMI JOIN\n* A semi join returns values from the left side of the relation that has a match with the right. It is also referred to as a left semi join.\n##### ANTI JOIN\n* An anti join returns values from the left relation that has no match with the right. It is also referred to as a left anti join."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"42508e7e-d468-4cc9-9545-03e36031db5c"}}},{"cell_type":"code","source":["emp_csv=spark.read.csv(\"/FileStore/tables/emp.csv\",header=True,inferSchema=True)\ndept_csv=spark.read.csv(\"/FileStore/tables/dept.csv\",header=True,inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26f42d15-bd42-497e-96ca-b19d508661f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["dept_csv.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96834d1e-45a8-438d-bc15-a6c1a2a89648"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Natural Joins\n* Natural joins make implicit guesses at the columns on which you would like to join. It finds matching columns and returns the results. Left, right, and outer natural joins are all supported.\n\n* Natural joins (perform a join by implicitly matching the columns between the two datasets with the same names)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9fcb575d-1727-403b-96df-b16610ccde07"}}},{"cell_type":"code","source":["#emp_csv.join(dept_csv,on =emp_csv['deptno'] == dept_csv['deptno'],how='inner').show()\nemp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'inner').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8379e804-7edb-478a-84c4-72918bb9e8ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+------+---------+----+--------+----+----+------+------+----------+--------+\n|EMPNO| ENAME|      JOB| MGR|HIREDATE| SAL|COMM|DEPTNO|Deptno|     Dname|     Loc|\n+-----+------+---------+----+--------+----+----+------+------+----------+--------+\n| 7369| SMITH|    CLERK|7902|17-12-80| 800|null|    20|    20|  RESEARCH|  DALLAS|\n| 7499| ALLEN| SALESMAN|7698|20-02-81|1600| 300|    30|    30|     SALES| CHICAGO|\n| 7521|  WARD| SALESMAN|7698|22-02-81|1250| 500|    30|    30|     SALES| CHICAGO|\n| 7566| JONES|  MANAGER|7839|02-04-81|2975|null|    20|    20|  RESEARCH|  DALLAS|\n| 7654|MARTIN| SALESMAN|7698|28-09-81|1250|1400|    30|    30|     SALES| CHICAGO|\n| 7698|   SGR|  MANAGER|7839|01-05-81|2850|null|    30|    30|     SALES| CHICAGO|\n| 7782|  RAVI|  MANAGER|7839|09-06-81|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n| 7788| SCOTT|  ANALYST|7566|19-04-87|3000|null|    20|    20|  RESEARCH|  DALLAS|\n| 7839|  KING|PRESIDENT|null|17-11-81|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n| 7844|TURNER| SALESMAN|7698|08-09-81|1500|   0|    30|    30|     SALES| CHICAGO|\n| 7876| ADAMS|    CLERK|7788|23-05-87|1100|null|    20|    20|  RESEARCH|  DALLAS|\n| 7900| JAMES|    CLERK|7698|03-12-81| 950|null|    30|    30|     SALES| CHICAGO|\n| 7902|  FORD|  ANALYST|7566|03-12-81|3000|null|    20|    20|  RESEARCH|  DALLAS|\n| 7934|MILLER|    CLERK|7782|23-01-82|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n+-----+------+---------+----+--------+----+----+------+------+----------+--------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------+---------+----+--------+----+----+------+------+----------+--------+\nEMPNO| ENAME|      JOB| MGR|HIREDATE| SAL|COMM|DEPTNO|Deptno|     Dname|     Loc|\n+-----+------+---------+----+--------+----+----+------+------+----------+--------+\n 7369| SMITH|    CLERK|7902|17-12-80| 800|null|    20|    20|  RESEARCH|  DALLAS|\n 7499| ALLEN| SALESMAN|7698|20-02-81|1600| 300|    30|    30|     SALES| CHICAGO|\n 7521|  WARD| SALESMAN|7698|22-02-81|1250| 500|    30|    30|     SALES| CHICAGO|\n 7566| JONES|  MANAGER|7839|02-04-81|2975|null|    20|    20|  RESEARCH|  DALLAS|\n 7654|MARTIN| SALESMAN|7698|28-09-81|1250|1400|    30|    30|     SALES| CHICAGO|\n 7698|   SGR|  MANAGER|7839|01-05-81|2850|null|    30|    30|     SALES| CHICAGO|\n 7782|  RAVI|  MANAGER|7839|09-06-81|2450|null|    10|    10|ACCOUNTING|NEW YORK|\n 7788| SCOTT|  ANALYST|7566|19-04-87|3000|null|    20|    20|  RESEARCH|  DALLAS|\n 7839|  KING|PRESIDENT|null|17-11-81|5000|null|    10|    10|ACCOUNTING|NEW YORK|\n 7844|TURNER| SALESMAN|7698|08-09-81|1500|   0|    30|    30|     SALES| CHICAGO|\n 7876| ADAMS|    CLERK|7788|23-05-87|1100|null|    20|    20|  RESEARCH|  DALLAS|\n 7900| JAMES|    CLERK|7698|03-12-81| 950|null|    30|    30|     SALES| CHICAGO|\n 7902|  FORD|  ANALYST|7566|03-12-81|3000|null|    20|    20|  RESEARCH|  DALLAS|\n 7934|MILLER|    CLERK|7782|23-01-82|1300|null|    10|    10|ACCOUNTING|NEW YORK|\n+-----+------+---------+----+--------+----+----+------+------+----------+--------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Outer Joins\n* Outer joins evaluate the keys in both of the DataFrames or tables and includes (and joins together) the rows that evaluate to true or false. If there is no equivalent row in either the left or right DataFrame, Spark will insert null:\n\n* Outer joins (keep rows with keys in either the left or right datasets)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c7f7c7c7-844e-4769-a170-6fce5f1c294d"}}},{"cell_type":"code","source":["emp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'full_outer').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67d12ae2-2460-4043-861d-32528ee3e5e4"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Left Outer Joins\n* Left outer joins evaluate the keys in both of the DataFrames or tables and includes all rows from the left DataFrame as well as any rows in the right DataFrame that have a match in the left DataFrame.\n\n* Left outer joins (keep rows with keys in the left dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c0e03fd-a997-4805-b429-4f859cbba28b"}}},{"cell_type":"code","source":["emp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'left_outer').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25c1fdac-859b-47c5-91a5-62fb9d7ba58c"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Right Outer Joins\n* Right outer joins evaluate the keys in both of the DataFrames or tables and includes all rows from the right DataFrame as well as any rows in the left DataFrame that have a match in the right DataFrame.\n\n* Right outer joins (keep rows with keys in the right dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"26f78c8c-3a32-4d2a-934f-d256a4a9b826"}}},{"cell_type":"code","source":["emp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'right').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d755e29-6696-4dae-937f-74ab6f9cbfbb"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Left Semi Joins\n* Semi joins are a bit of a departure from the other joins. They do not actually include any values from the right DataFrame. They only compare values to see if the value exists in the second DataFrame. If the value does exist, those rows will be kept in the result, even if there are duplicate keys in the left DataFrame.\n\n* Left semi joins (keep the rows in the left, and only the left, dataset where the key appears in the right dataset)\n\n\n##### The essential differences between a semi join and a regular join are:\n\n* Semi join either returns each row from input A, or it does not. No row duplication can occur.\n* Regular join duplicates rows if there are multiple matches on the join predicate.\n* Semi join is defined to only return columns from input A.\n* Regular join may return columns from either (or both) join inputs."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3f2d149-b2af-4d43-a84c-1be8522d2d9b"}}},{"cell_type":"code","source":["emp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'semi').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ceb9c08-4f56-44f2-b8b6-345ca0dc2365"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nselect * from joins.emp e where exists (select * From joins.dept d where e.deptno = d.deptno)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c008e2e-da8f-4189-a772-66b073878797"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Left Anti Joins\n* Left anti joins are the opposite of left semi joins. Like left semi joins, they do not actually include any values from the right DataFrame.\n* They only compare values to see if the value exists in the second DataFrame.\n* However, rather than keeping the values that exist in the second DataFrame, they keep only the values that do not have a corresponding key in the second DataFrame.\n\n* Left anti joins (keep the rows in the left, and only the left, dataset where they do not appear in the right dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5aa47983-2a9a-4a06-91db-0b43654f23ba"}}},{"cell_type":"code","source":["emp_csv.join(dept_csv,emp_csv['deptno'] == dept_csv['deptno'],'anti').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4d89554b-2cbc-4a47-b7f7-b5a4483528a5"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Cross (Cartesian) Joins\n* The last of our joins are cross-joins or cartesian products. Cross-joins in simplest terms are inner joins that do not specify a predicate. Cross joins will join every single row in the left DataFrame to ever single row in the right DataFrame\n\n* Cross (or Cartesian) joins (match every row in the left dataset with every row in the right dataset)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"acee4e9d-c7d0-48cc-97c9-efc39a96728f"}}},{"cell_type":"code","source":["emp_csv.crossJoin(dept_csv).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c33d1014-b7c8-46fc-9c7c-83259b9afa83"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## SQL JOINS"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"180ebd15-61db-4690-81aa-65853b048a86"}}},{"cell_type":"markdown","source":["###### Creating database name as `JOINS`  if not exists for validatinng joins for both `EMP` and `DEPT` tables"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e90ffba4-1a17-434b-8e15-99ee525315d0"}}},{"cell_type":"code","source":["%sql\ncreate database if not exists joins"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"225d3f90-efda-4dfa-99d6-20b84f783652"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Creating `EMP` and `DEPT` tables using EMP_CSV and DEPT_CSV Dataframes which is created from files."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ddfe651b-d729-42a6-a516-9e44e6a22567"}}},{"cell_type":"code","source":["emp_csv=spark.read.csv(\"/FileStore/tables/emp.csv\",header=True,inferSchema=True)\ndept_csv=spark.read.csv(\"/FileStore/tables/dept.csv\",header=True,inferSchema=True)\nemp_csv.write.mode('overwrite').saveAsTable('joins.emp')\ndept_csv.write.mode('overwrite').saveAsTable('joins.dept')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3db6267d-abc1-4260-9fc0-a478627c4afb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate different type of joins.\n-- Use emp and dept tables to demonstrate inner join.\n\nSELECT * FROM joins.emp  INNER JOIN joins.dept on emp.deptno = dept.deptno "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8652ca4-16a7-46fc-9767-3564fe2daed5"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate left join.\nSELECT *  FROM joins.emp LEFT JOIN joins.dept ON emp.deptno = dept.deptno;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e271986-14b4-458a-902f-191c9b626437"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate right join.\nSELECT *  FROM joins.emp RIGHT JOIN joins.dept ON emp.deptno = dept.deptno;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c268fe7c-231b-40de-a46d-270018d1a1b7"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate full join.\nSELECT *  FROM joins.emp FULL JOIN joins.dept ON emp.deptno = dept.deptno;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"733e2978-996b-4321-ac7b-939225b761cc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate cross join.\nSELECT empno, ename, emp.deptno, dname FROM joins.emp CROSS JOIN joins.dept;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e144d79c-99fe-42ca-b81c-bf56d7d06eb9"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate semi join. we can use LEFT SEMI JOIN or   SEMI JOIN\nSELECT * FROM joins.emp  SEMI JOIN joins.dept ON emp.deptno = dept.deptno; "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52bff589-16e5-4b8a-b5e8-dde455115709"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Use emp and dept tables to demonstrate anti join. we can use LEFT ANTI JOIN or ANTI JOIN\nSELECT * FROM joins.emp  ANTI JOIN joins.dept ON emp.deptno = dept.deptno; "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d08ebedb-4af3-4448-8baf-d7cba3c899de"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Broadcast join\n* Little table–to–little table\n* When performing joins with small tables, it’s usually best to let Spark decide how to join them.\n* You can always force a broadcast join if you’re noticing strange behavior.\n* Broadcast joins are easier to run on a cluster. Spark can “broadcast” a small DataFrame by sending all the data in that small DataFrame to all nodes in the cluster. After the small DataFrame is broadcasted, Spark can perform a join without shuffling any of the data in the large DataFrame."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0814f6fa-8be0-45fa-afcb-58a9e85680db"}}},{"cell_type":"code","source":["\nfrom pyspark.sql.functions import broadcast \n\nemp_csv.join(broadcast(dept_csv),emp_csv['deptno']==dept_csv['deptno']).explain() # Marks a DataFrame as small enough for use in broadcast joins."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0d5f6d50-25db-48c9-ad25-de8ca9bd2a6c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as f\nemp_csv.persist()\nemp_csv.filter(f.col('comm').isNull()).select('*').show() # Marks a DataFrame as small enough for use in broadcast joins."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"41c86772-ce2a-4950-bee6-e06058e7ebe4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n--We accept BROADCAST, BROADCASTJOIN and MAPJOIN for broadcast hint\nSELECT /*+ BROADCAST(r) */ * FROM records r JOIN src s ON r.key = s.key"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94a5ae97-ed88-45cb-bb2f-cb3fd0323a78"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Coalesce Hints for SQL Queries\n* Coalesce hints allows the Spark SQL users to control the number of output files just like the coalesce, repartition and repartitionByRange in Dataset API, they can be used for performance tuning and reducing the number of output files. The “COALESCE” hint only has a partition number as a parameter. The “REPARTITION” hint has a partition number, columns, or both of them as parameters. The “REPARTITION_BY_RANGE” hint must have column names and a partition number is optional."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e78fff89-4446-4e72-b888-31b6e16e8abe"}}},{"cell_type":"code","source":["emp_csv.write.format('parquet').mode('overwrite').partitionBy('DEPTNO').saveAsTable('joins.emp')\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e5188718-41b0-4e7c-97f8-69832809a0a4"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nshow create table joins.emp"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c2b98358-2139-492f-8877-b46df49d3bba"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\n--EXPLAIN   SELECT /*+ COALESCE(3) */ * FROM joins.emp where deptno=10;\n--EXPLAIN SELECT /*+ REPARTITION(3) */ * FROM joins.emp where deptno=10;\nEXPLAIN SELECT /*+ REPARTITION(deptno) */ * FROM joins.emp where deptno=20;\n--SELECT /*+ REPARTITION(3, deptno) */ * FROM joins.emp;\n--SELECT /*+ REPARTITION_BY_RANGE(deptno) */ * FROM joins.emp;\n--SELECT /*+ REPARTITION_BY_RANGE(3, deptno) */ * FROM joins.emp;"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"798065a6-90c4-4824-9353-7fc9e65133cc"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Join Hints Types\n\n#### BROADCAST\n\n* Suggests that Spark use broadcast join. The join side with the hint will be broadcast regardless of autoBroadcastJoinThreshold. If both sides of the join have the broadcast hints, the one with the smaller size (based on stats) will be broadcast. The aliases for BROADCAST are BROADCASTJOIN and MAPJOIN.\n\n#### MERGE\n\n* Suggests that Spark use shuffle sort merge join. The aliases for MERGE are SHUFFLE_MERGE and MERGEJOIN.\n\n#### SHUFFLE_HASH\n\n* Suggests that Spark use shuffle hash join. If both sides have the shuffle hash hints, Spark chooses the smaller side (based on stats) as the build side.\n\n#### SHUFFLE_REPLICATE_NL\n\n* Suggests that Spark use shuffle-and-replicate nested loop join."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb5bd30e-92dd-455b-92f4-0a2694a77235"}}},{"cell_type":"code","source":["%sql\nANALYZE TABLE joins.dept COMPUTE STATISTICS noscan"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2fe221b6-83fa-43be-a76c-30ce5eb0cf77"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\nSELECT * FROM joins.emp   JOIN joins.dept ON emp.deptno = dept.deptno;\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2dec9c8f-0378-4f2e-b85d-1c8f2f981e2d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[[7499,"ALLEN","SALESMAN",7698,"20-02-81",1600,300,30,30,"SALES","CHICAGO"],[7521,"WARD","SALESMAN",7698,"22-02-81",1250,500,30,30,"SALES","CHICAGO"],[7654,"MARTIN","SALESMAN",7698,"28-09-81",1250,1400,30,30,"SALES","CHICAGO"],[7698,"SGR","MANAGER",7839,"01-05-81",2850,null,30,30,"SALES","CHICAGO"],[7844,"TURNER","SALESMAN",7698,"08-09-81",1500,0,30,30,"SALES","CHICAGO"],[7900,"JAMES","CLERK",7698,"03-12-81",950,null,30,30,"SALES","CHICAGO"],[7369,"SMITH","CLERK",7902,"17-12-80",800,null,20,20,"RESEARCH","DALLAS"],[7566,"JONES","MANAGER",7839,"02-04-81",2975,null,20,20,"RESEARCH","DALLAS"],[7788,"SCOTT","ANALYST",7566,"19-04-87",3000,null,20,20,"RESEARCH","DALLAS"],[7876,"ADAMS","CLERK",7788,"23-05-87",1100,null,20,20,"RESEARCH","DALLAS"],[7902,"FORD","ANALYST",7566,"03-12-81",3000,null,20,20,"RESEARCH","DALLAS"],[7782,"RAVI","MANAGER",7839,"09-06-81",2450,null,10,10,"ACCOUNTING","NEW YORK"],[7839,"KING","PRESIDENT",null,"17-11-81",5000,null,10,10,"ACCOUNTING","NEW YORK"],[7934,"MILLER","CLERK",7782,"23-01-82",1300,null,10,10,"ACCOUNTING","NEW YORK"]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"name":"EMPNO","type":"\"integer\"","metadata":"{}"},{"name":"ENAME","type":"\"string\"","metadata":"{}"},{"name":"JOB","type":"\"string\"","metadata":"{}"},{"name":"MGR","type":"\"integer\"","metadata":"{}"},{"name":"HIREDATE","type":"\"string\"","metadata":"{}"},{"name":"SAL","type":"\"integer\"","metadata":"{}"},{"name":"COMM","type":"\"integer\"","metadata":"{}"},{"name":"DEPTNO","type":"\"integer\"","metadata":"{}"},{"name":"Deptno","type":"\"integer\"","metadata":"{}"},{"name":"Dname","type":"\"string\"","metadata":"{}"},{"name":"Loc","type":"\"string\"","metadata":"{}"}],"aggError":"","aggData":[],"addedWidgets":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>EMPNO</th><th>ENAME</th><th>JOB</th><th>MGR</th><th>HIREDATE</th><th>SAL</th><th>COMM</th><th>DEPTNO</th><th>Deptno</th><th>Dname</th><th>Loc</th></tr></thead><tbody><tr><td>7499</td><td>ALLEN</td><td>SALESMAN</td><td>7698</td><td>20-02-81</td><td>1600</td><td>300</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7521</td><td>WARD</td><td>SALESMAN</td><td>7698</td><td>22-02-81</td><td>1250</td><td>500</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7654</td><td>MARTIN</td><td>SALESMAN</td><td>7698</td><td>28-09-81</td><td>1250</td><td>1400</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7698</td><td>SGR</td><td>MANAGER</td><td>7839</td><td>01-05-81</td><td>2850</td><td>null</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7844</td><td>TURNER</td><td>SALESMAN</td><td>7698</td><td>08-09-81</td><td>1500</td><td>0</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7900</td><td>JAMES</td><td>CLERK</td><td>7698</td><td>03-12-81</td><td>950</td><td>null</td><td>30</td><td>30</td><td>SALES</td><td>CHICAGO</td></tr><tr><td>7369</td><td>SMITH</td><td>CLERK</td><td>7902</td><td>17-12-80</td><td>800</td><td>null</td><td>20</td><td>20</td><td>RESEARCH</td><td>DALLAS</td></tr><tr><td>7566</td><td>JONES</td><td>MANAGER</td><td>7839</td><td>02-04-81</td><td>2975</td><td>null</td><td>20</td><td>20</td><td>RESEARCH</td><td>DALLAS</td></tr><tr><td>7788</td><td>SCOTT</td><td>ANALYST</td><td>7566</td><td>19-04-87</td><td>3000</td><td>null</td><td>20</td><td>20</td><td>RESEARCH</td><td>DALLAS</td></tr><tr><td>7876</td><td>ADAMS</td><td>CLERK</td><td>7788</td><td>23-05-87</td><td>1100</td><td>null</td><td>20</td><td>20</td><td>RESEARCH</td><td>DALLAS</td></tr><tr><td>7902</td><td>FORD</td><td>ANALYST</td><td>7566</td><td>03-12-81</td><td>3000</td><td>null</td><td>20</td><td>20</td><td>RESEARCH</td><td>DALLAS</td></tr><tr><td>7782</td><td>RAVI</td><td>MANAGER</td><td>7839</td><td>09-06-81</td><td>2450</td><td>null</td><td>10</td><td>10</td><td>ACCOUNTING</td><td>NEW YORK</td></tr><tr><td>7839</td><td>KING</td><td>PRESIDENT</td><td>null</td><td>17-11-81</td><td>5000</td><td>null</td><td>10</td><td>10</td><td>ACCOUNTING</td><td>NEW YORK</td></tr><tr><td>7934</td><td>MILLER</td><td>CLERK</td><td>7782</td><td>23-01-82</td><td>1300</td><td>null</td><td>10</td><td>10</td><td>ACCOUNTING</td><td>NEW YORK</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sql\n-- Join Hints for broadcast join\nSELECT /*+ BROADCAST(joins.dept) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\nSELECT /*+ BROADCASTJOIN (joins.emp) */ * FROM joins.emp left JOIN joins.dept ON emp.deptno = dept.deptno;\nSELECT /*+ MAPJOIN(joins.dept) */ * FROM joins.emp right JOIN joins.dept ON emp.deptno = dept.deptno;\n\n-- Join Hints for shuffle sort merge join\nSELECT /*+ SHUFFLE_MERGE(joins.emp) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\nSELECT /*+ MERGEJOIN(joins.dept) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\nSELECT /*+ MERGE(joins.emp) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\n\n-- Join Hints for shuffle hash join\nSELECT /*+ SHUFFLE_HASH(joins.emp) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\n\n-- Join Hints for shuffle-and-replicate nested loop join\nSELECT /*+ SHUFFLE_REPLICATE_NL(joins.emp) */ * FROM joins.emp INNER JOIN joins.dept ON emp.deptno = dept.deptno;\n\n-- When different join strategy hints are specified on both sides of a join, Spark\n-- prioritizes the BROADCAST hint over the MERGE hint over the SHUFFLE_HASH hint\n-- over the SHUFFLE_REPLICATE_NL hint.\n-- Spark will issue Warning in the following example\n-- org.apache.spark.sql.catalyst.analysis.HintErrorLogger: Hint (strategy=merge)\n-- is overridden by another hint and will not take effect.\nSELECT /*+ BROADCAST(joins.dept), MERGE(joins.emp, joins.dept) */ * FROM t1 INNER JOIN t2 ON t1.key = t2.key;\n\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1ff111a-09d9-4098-bc1f-83aedcbb8788"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df1 = spark.range(2, 1000000, 2)\ndf2 = spark.range(2, 1000000, 4)\nstep1 = df1.repartition(5)\nstep12 = df2.repartition(6)\nstep2 = step1.selectExpr(\"id * 5 as id\")\nstep3 = step2.join(step12, [\"id\"])\nstep4 = step3.selectExpr(\"sum(id)\")\nstep4.explain()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9088d736-b08c-4fb2-89db-b065d1970624"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[], functions=[finalmerge_sum(merge sum#6663L) AS sum(id#6656L)#6659L])\n   +- Exchange SinglePartition, true, [id=#8404]\n      +- HashAggregate(keys=[], functions=[partial_sum(id#6656L) AS sum#6663L])\n         +- Project [id#6656L]\n            +- BroadcastHashJoin [id#6656L], [id#6650L], Inner, BuildRight\n               :- Project [(id#6648L * 5) AS id#6656L]\n               :  +- Exchange RoundRobinPartitioning(5), false, [id=#8390]\n               :     +- Range (2, 1000000, step=2, splits=8)\n               +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false])), [id=#8399]\n                  +- Exchange RoundRobinPartitioning(6), false, [id=#8393]\n                     +- Range (2, 1000000, step=4, splits=8)\n\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- HashAggregate(keys=[], functions=[finalmerge_sum(merge sum#6663L) AS sum(id#6656L)#6659L])\n   +- Exchange SinglePartition, true, [id=#8404]\n      +- HashAggregate(keys=[], functions=[partial_sum(id#6656L) AS sum#6663L])\n         +- Project [id#6656L]\n            +- BroadcastHashJoin [id#6656L], [id#6650L], Inner, BuildRight\n               :- Project [(id#6648L * 5) AS id#6656L]\n               :  +- Exchange RoundRobinPartitioning(5), false, [id=#8390]\n               :     +- Range (2, 1000000, step=2, splits=8)\n               +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, bigint, false])), [id=#8399]\n                  +- Exchange RoundRobinPartitioning(6), false, [id=#8393]\n                     +- Range (2, 1000000, step=4, splits=8)\n\n\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Tutorial_4_Joins","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3440991690248733}},"nbformat":4,"nbformat_minor":0}
